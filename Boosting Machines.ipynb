{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from mypipes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file=r'C:\\\\Users\\\\Larry Williams\\\\Desktop\\\\Mamata\\\\Edvancer\\\\data\\\\data\\\\rg_train.csv'\n",
    "test_file=r'C:\\\\Users\\\\Larry Williams\\\\Desktop\\\\Mamata\\\\Edvancer\\\\data\\\\data\\\\rg_test.csv'\n",
    "bd_train=pd.read_csv(train_file)\n",
    "\n",
    "bd_test=pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars=list(bd_train.select_dtypes(exclude=['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars=[_ for _ in num_vars if _ not in ['REF_NO','Revenue.Grid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars=list(bd_train.select_dtypes(include=['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars=[_ for _ in cat_vars if _ not in \n",
    "          ['children','age_band', 'post_code','post_area','family_income']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=pdPipeline([\n",
    "    ('var_select',VarSelector(num_vars)),\n",
    "    ('missing_trt',DataFrameImputer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2=pdPipeline([\n",
    "    ('var_select',VarSelector(cat_vars)),\n",
    "    ('missing_trt',DataFrameImputer()),\n",
    "    ('create_dummies',get_dummies_Pipe(70))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3=pdPipeline([\n",
    "    ('var_select',VarSelector(['age_band'])),\n",
    "    ('custom_fico',custom_age_band()),\n",
    "    ('missing_trt',DataFrameImputer())\n",
    "])\n",
    "\n",
    "p4=pdPipeline([\n",
    "    ('var_select',VarSelector(['family_income'])),\n",
    "    ('custom_fico',custom_family_income()),\n",
    "    ('missing_trt',DataFrameImputer())\n",
    "])\n",
    "\n",
    "p5=pdPipeline([\n",
    "    ('var_select',VarSelector(['children'])),\n",
    "    ('string_clean1',string_clean(replace_it='Zero',replace_with='0')),\n",
    "    ('string_clean2',string_clean(replace_it='4+',replace_with='4')),\n",
    "    ('convert_to_numeric',convert_to_numeric()),\n",
    "    ('missing_trt',DataFrameImputer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe=FeatureUnion([\n",
    "    ('num',p1),\n",
    "    ('obj_to_dum',p2),\n",
    "    ('age_band',p3),\n",
    "    ('family_income',p4),\n",
    "    ('children',p5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=pd.DataFrame(data=data_pipe.fit_transform(bd_train),\n",
    "                     columns=data_pipe.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=pd.DataFrame(data=data_pipe.transform(bd_test),\n",
    "                     columns=data_pipe.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=(bd_train['Revenue.Grid']==1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 71)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_params={'n_estimators':[50,100,200,500,700],\n",
    "           'learning_rate': [0.01,.05,0.1,0.4,0.8,1],\n",
    "            'max_depth':[1,2,3,4,5,6],\n",
    "#             'min_samples_split':[2,5,10,20],\n",
    "#             'min_samples_leaf':[2,5,10,20],\n",
    "            'subsample':[0.5,0.8,1],\n",
    "            'max_features':[5,10,15,20,30,45,55,65]\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm=GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search=RandomizedSearchCV(gbm,\n",
    "                                 scoring='roc_auc',\n",
    "                                 param_distributions=gbm_params,\n",
    "                                 cv=10,\n",
    "                                 n_iter=10,\n",
    "                                 n_jobs=-1,\n",
    "                                verbose=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   45.8s\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:   46.8s\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:   49.3s\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:   50.4s\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   54.4s\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:   57.6s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:   59.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                   estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                        criterion='friedman_mse',\n",
       "                                                        init=None,\n",
       "                                                        learning_rate=0.1,\n",
       "                                                        loss='deviance',\n",
       "                                                        max_depth=3,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        n_estimators=100,\n",
       "                                                        n_it...\n",
       "                                                        warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.05, 0.1, 0.4,\n",
       "                                                          0.8, 1],\n",
       "                                        'max_depth': [1, 2, 3, 4, 5, 6],\n",
       "                                        'max_features': [5, 10, 15, 20, 30, 45,\n",
       "                                                         55, 65],\n",
       "                                        'n_estimators': [50, 100, 200, 500,\n",
       "                                                         700],\n",
       "                                        'subsample': [0.5, 0.8, 1]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.05, loss='deviance', max_depth=5,\n",
    "              max_features=20, max_leaf_nodes=None,\n",
    "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=700,\n",
    "              n_iter_no_change=None, presort='auto', random_state=None,\n",
    "              subsample=0.5, tol=0.0001, validation_fraction=0.1,\n",
    "              verbose=0, warm_start=False)\n",
    "              \n",
    "use the above result in the class, its a result from previous run. This can be definitely different on a rerun. use this to save time in class so that you dont have to wait for the randomised search to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.5f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.990 (std: 0.00225)\n",
      "Parameters: {'subsample': 0.8, 'n_estimators': 500, 'max_features': 45, 'max_depth': 5, 'learning_rate': 0.1}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.984 (std: 0.00564)\n",
      "Parameters: {'subsample': 1, 'n_estimators': 700, 'max_features': 5, 'max_depth': 4, 'learning_rate': 0.4}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.973 (std: 0.00478)\n",
      "Parameters: {'subsample': 1, 'n_estimators': 50, 'max_features': 55, 'max_depth': 6, 'learning_rate': 0.01}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.966 (std: 0.03738)\n",
      "Parameters: {'subsample': 1, 'n_estimators': 700, 'max_features': 45, 'max_depth': 4, 'learning_rate': 0.8}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.958 (std: 0.01015)\n",
      "Parameters: {'subsample': 0.5, 'n_estimators': 200, 'max_features': 55, 'max_depth': 1, 'learning_rate': 0.1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search.cv_results_,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top 5 classfiers from the previous run were as follows : \n",
    "\n",
    "Model with rank: 1\n",
    "\n",
    "Mean validation score: 0.925 (std: 0.00188)\n",
    "\n",
    "Parameters: {'max_features': 20, 'max_depth': 3, 'subsample': 0.8, 'learning_rate': 0.4, 'n_estimators': 100}\n",
    "\n",
    "~~~~~~~~~~\n",
    "\n",
    "Model with rank: 2\n",
    "\n",
    "Mean validation score: 0.924 (std: 0.00121)\n",
    "\n",
    "Parameters: {'max_features': 15, 'max_depth': 4, 'subsample': 1, 'learning_rate': 0.4, 'n_estimators': 100}\n",
    "\n",
    "~~~~~~~~~~\n",
    "\n",
    "Model with rank: 3\n",
    "\n",
    "Mean validation score: 0.923 (std: 0.00250)\n",
    "\n",
    "Parameters: {'max_features': 5, 'max_depth': 4, 'subsample': 0.5, 'learning_rate': 0.05, 'n_estimators': 500}\n",
    "\n",
    "~~~~~~~~~~\n",
    "\n",
    "Model with rank: 4\n",
    "\n",
    "Mean validation score: 0.914 (std: 0.00290)\n",
    "\n",
    "Parameters: {'max_features': 10, 'max_depth': 5, 'subsample': 1, 'learning_rate': 0.05, 'n_estimators': 50}\n",
    "\n",
    "~~~~~~~~~~\n",
    "\n",
    "Model with rank: 5\n",
    "\n",
    "Mean validation score: 0.913 (std: 0.00174)\n",
    "\n",
    "Parameters: {'max_features': 30, 'max_depth': 5, 'subsample': 0.8, 'learning_rate': 0.4, 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tentative performance : 0.925 for the best classfier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: you can use the random search predict,predict_proba function to make prediction as randomisedsearchcv automatically fits the best candidate on complete data. If you want to look into feature_importance etc, then fit the best estimator separately**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {  \n",
    "                \"learning_rate\":[0.01,0.05,0.1,0.3,0.5],\n",
    "                \"gamma\":[i/10.0 for i in range(0,5)],\n",
    "                \"max_depth\": [2,3,4,5,6,7,8],\n",
    "                \"min_child_weight\":[1,2,5,10],\n",
    "                \"max_delta_step\":[0,1,2,5,10],\n",
    "                \"subsample\":[i/10.0 for i in range(5,10)],\n",
    "                \"colsample_bytree\":[i/10.0 for i in range(5,10)],\n",
    "                \"colsample_bylevel\":[i/10.0 for i in range(5,10)],\n",
    "                \"reg_lambda\":[1e-5, 1e-2, 0.1, 1, 100], \n",
    "                \"reg_alpha\":[1e-5, 1e-2, 0.1, 1, 100],\n",
    "                \"scale_pos_weight\":[1,2,3,4,5,6,7,8,9],\n",
    "                \"n_estimators\":[100,500,700,1000]\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=XGBClassifier(objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter=10\n",
    "\n",
    "random_search=RandomizedSearchCV(xgb,n_jobs=-1,cv=10,n_iter=n_iter,scoring='roc_auc',\n",
    "                                 param_distributions=xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:12:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           enable_categorical=False, gamma=None,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           mon...\n",
       "                                        'max_delta_step': [0, 1, 2, 5, 10],\n",
       "                                        'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
       "                                        'min_child_weight': [1, 2, 5, 10],\n",
       "                                        'n_estimators': [100, 500, 700, 1000],\n",
       "                                        'reg_alpha': [1e-05, 0.01, 0.1, 1, 100],\n",
       "                                        'reg_lambda': [1e-05, 0.01, 0.1, 1,\n",
       "                                                       100],\n",
       "                                        'scale_pos_weight': [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9],\n",
       "                                        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.991 (std: 0.00198)\n",
      "Parameters: {'subsample': 0.9, 'scale_pos_weight': 8, 'reg_lambda': 0.01, 'reg_alpha': 1, 'n_estimators': 700, 'min_child_weight': 5, 'max_depth': 5, 'max_delta_step': 1, 'learning_rate': 0.05, 'gamma': 0.0, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.5}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.991 (std: 0.00197)\n",
      "Parameters: {'subsample': 0.9, 'scale_pos_weight': 5, 'reg_lambda': 100, 'reg_alpha': 1, 'n_estimators': 700, 'min_child_weight': 2, 'max_depth': 4, 'max_delta_step': 0, 'learning_rate': 0.5, 'gamma': 0.2, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.7}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.990 (std: 0.00198)\n",
      "Parameters: {'subsample': 0.5, 'scale_pos_weight': 7, 'reg_lambda': 100, 'reg_alpha': 0.1, 'n_estimators': 700, 'min_child_weight': 10, 'max_depth': 6, 'max_delta_step': 10, 'learning_rate': 0.3, 'gamma': 0.1, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.7}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: 0.990 (std: 0.00214)\n",
      "Parameters: {'subsample': 0.8, 'scale_pos_weight': 7, 'reg_lambda': 1e-05, 'reg_alpha': 1e-05, 'n_estimators': 700, 'min_child_weight': 2, 'max_depth': 5, 'max_delta_step': 0, 'learning_rate': 0.5, 'gamma': 0.3, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.7}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: 0.985 (std: 0.00412)\n",
      "Parameters: {'subsample': 0.6, 'scale_pos_weight': 7, 'reg_lambda': 1e-05, 'reg_alpha': 0.01, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 3, 'max_delta_step': 1, 'learning_rate': 0.5, 'gamma': 0.1, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.8}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search.cv_results_,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top 5 classfiers from the previous run \n",
    "\n",
    "Model with rank: 1\n",
    "\n",
    "Mean validation score: 0.928 (std: 0.00232)\n",
    "\n",
    "Parameters: {'reg_lambda': 1e-05, 'subsample': 0.9, 'reg_alpha': 1, 'max_depth': 8, 'min_child_weight': 10, 'n_estimators': 1000, 'gamma': 0.1, 'colsample_bylevel': 0.8, 'scale_pos_weight': 2, 'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_delta_step': 10}\n",
    "\n",
    "____\n",
    "\n",
    "Model with rank: 2\n",
    "\n",
    "Mean validation score: 0.927 (std: 0.00160)\n",
    "\n",
    "Parameters: {'reg_lambda': 1, 'subsample': 0.6, 'reg_alpha': 0.1, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 1000, 'gamma': 0.3, 'colsample_bylevel': 0.9, 'scale_pos_weight': 2, 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_delta_step': 5}\n",
    "\n",
    "____\n",
    "\n",
    "Model with rank: 3\n",
    "\n",
    "Mean validation score: 0.926 (std: 0.00101)\n",
    "\n",
    "Parameters: {'reg_lambda': 0.1, 'subsample': 0.7, 'reg_alpha': 1e-05, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 500, 'gamma': 0.2, 'colsample_bylevel': 0.5, 'scale_pos_weight': 3, 'colsample_bytree': 0.9, 'learning_rate': 0.1, 'max_delta_step': 1}\n",
    "\n",
    "____\n",
    "\n",
    "Model with rank: 4\n",
    "\n",
    "Mean validation score: 0.925 (std: 0.00104)\n",
    "\n",
    "Parameters: {'reg_lambda': 0.1, 'subsample': 0.9, 'reg_alpha': 0.01, 'max_depth': 6, 'min_child_weight': 2, 'n_estimators': 1000, 'gamma': 0.2, 'colsample_bylevel': 0.8, 'scale_pos_weight': 8, 'colsample_bytree': 0.5, 'learning_rate': 0.05, 'max_delta_step': 0}\n",
    "\n",
    "____\n",
    "\n",
    "Model with rank: 5\n",
    "\n",
    "Mean validation score: 0.920 (std: 0.00278)\n",
    "\n",
    "Parameters: {'reg_lambda': 1, 'subsample': 0.8, 'reg_alpha': 0.1, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 500, 'gamma': 0.0, 'colsample_bylevel': 0.5, 'scale_pos_weight': 8, 'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_delta_step': 5}\n",
    "\n",
    "____\n",
    "\n",
    "tentative performance of best estimator : 0.928\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.5,\n",
       "              colsample_bynode=1, colsample_bytree=0.7,\n",
       "              enable_categorical=False, gamma=0.0, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.05, max_delta_step=1, max_depth=5,\n",
       "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=700, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='binary:logistic', predictor='auto', random_state=0,\n",
       "              reg_alpha=1, reg_lambda=0.01, scale_pos_weight=8, subsample=0.9,\n",
       "              tree_method='exact', use_label_encoder=True,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best estimator from the previous run can be copied from here :\n",
    "\n",
    "XGBClassifier(base_score=0.5, colsample_bylevel=0.8, colsample_bytree=0.5,\n",
    "       gamma=0.1, learning_rate=0.01, max_delta_step=10, max_depth=8,\n",
    "       min_child_weight=10, missing=None, n_estimators=1000, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=1, reg_lambda=1e-05,\n",
    "       scale_pos_weight=2, seed=0, silent=True, subsample=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Parameter tuning for xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we tune all the paramters together , there are chances that our results will be much far from the best. There are many parameters where variation doesnt impact the performance too much and we can tune them later once we have fixed values of parameters with volatile performance.\n",
    "\n",
    "As a general strtaegy we can start with tuning numer of trees or n_estimators , in case of boosting machines , learning_rate is directly related with n_estimators . A very low learning_rate will need high number of n_estimators . We can start with a decent fixed learning rate and tune n_estimaors for it. \n",
    "\n",
    "All can be left as default for now except subsample , colsample_bytree and colsample_bylevel, these are set to default=1, we'll take a more conservative value 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {  \n",
    "                \"n_estimators\":[100,500,700,900,1000,1200,1500]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1=XGBClassifier(subsample=0.8,\n",
    "                   colsample_bylevel=0.8,\n",
    "                   colsample_bytree=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search=GridSearchCV(xgb1,cv=10,\n",
    "                         param_grid=xgb_params,\n",
    "                         scoring='roc_auc',\n",
    "                         verbose=20)\n",
    "\n",
    "# two issues : currently xgboost is not running with multicores \n",
    "# mac issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n",
      "[CV] n_estimators=100 ................................................\n",
      "[15:30:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=100, score=0.992, total=   1.2s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[15:30:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=100, score=0.987, total=   1.2s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[15:30:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=100, score=0.990, total=   1.2s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[15:30:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=100, score=0.992, total=   1.2s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[15:30:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=100, score=0.992, total=   1.2s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[15:30:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=100, score=0.992, total=   1.3s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[15:30:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    7.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=100, score=0.990, total=   1.2s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[15:30:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    8.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=100, score=0.987, total=   1.4s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[15:30:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    9.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=100, score=0.989, total=   1.2s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[15:30:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   11.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=100, score=0.990, total=   1.1s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[15:30:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   12.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=500, score=0.989, total=   4.6s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[15:30:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:   16.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=500, score=0.987, total=   5.0s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[15:30:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   21.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=500, score=0.990, total=   4.9s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[15:30:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:   26.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=500, score=0.993, total=   4.7s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[15:30:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:   31.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=500, score=0.991, total=   4.5s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[15:31:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   36.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=500, score=0.993, total=   4.4s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[15:31:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:   40.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=500, score=0.990, total=   4.4s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[15:31:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:   44.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=500, score=0.991, total=   5.1s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[15:31:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:   50.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=500, score=0.990, total=   4.4s\n",
      "[CV] n_estimators=500 ................................................\n",
      "[15:31:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:   54.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=500, score=0.991, total=   5.1s\n",
      "[CV] n_estimators=700 ................................................\n",
      "[15:31:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=700, score=0.989, total=   7.9s\n",
      "[CV] n_estimators=700 ................................................\n",
      "[15:31:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=700, score=0.987, total=   6.9s\n",
      "[CV] n_estimators=700 ................................................\n",
      "[15:31:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=700, score=0.989, total=   8.6s\n",
      "[CV] n_estimators=700 ................................................\n",
      "[15:31:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=700, score=0.993, total=   6.3s\n",
      "[CV] n_estimators=700 ................................................\n",
      "[15:31:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=700, score=0.991, total=   7.1s\n",
      "[CV] n_estimators=700 ................................................\n",
      "[15:32:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=700, score=0.993, total=   6.9s\n",
      "[CV] n_estimators=700 ................................................\n",
      "[15:32:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=700, score=0.990, total=   7.9s\n",
      "[CV] n_estimators=700 ................................................\n",
      "[15:32:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=700, score=0.991, total=   6.3s\n",
      "[CV] n_estimators=700 ................................................\n",
      "[15:32:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=700, score=0.990, total=   6.3s\n",
      "[CV] n_estimators=700 ................................................\n",
      "[15:32:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=700, score=0.991, total=   6.8s\n",
      "[CV] n_estimators=900 ................................................\n",
      "[15:32:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=900, score=0.988, total=  10.6s\n",
      "[CV] n_estimators=900 ................................................\n",
      "[15:32:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=900, score=0.987, total=  10.5s\n",
      "[CV] n_estimators=900 ................................................\n",
      "[15:32:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=900, score=0.989, total=   9.2s\n",
      "[CV] n_estimators=900 ................................................\n",
      "[15:33:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=900, score=0.993, total=   8.2s\n",
      "[CV] n_estimators=900 ................................................\n",
      "[15:33:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=900, score=0.991, total=  10.0s\n",
      "[CV] n_estimators=900 ................................................\n",
      "[15:33:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=900, score=0.993, total=   8.2s\n",
      "[CV] n_estimators=900 ................................................\n",
      "[15:33:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=900, score=0.990, total=   8.0s\n",
      "[CV] n_estimators=900 ................................................\n",
      "[15:33:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=900, score=0.991, total=   7.9s\n",
      "[CV] n_estimators=900 ................................................\n",
      "[15:33:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=900, score=0.990, total=   7.8s\n",
      "[CV] n_estimators=900 ................................................\n",
      "[15:33:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] .................... n_estimators=900, score=0.990, total=   7.8s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[15:34:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1000, score=0.988, total=   8.8s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[15:34:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1000, score=0.986, total=   8.5s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[15:34:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1000, score=0.989, total=   9.0s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[15:34:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1000, score=0.994, total=   9.4s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[15:34:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1000, score=0.991, total=   9.5s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[15:34:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1000, score=0.993, total=   9.0s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[15:35:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1000, score=0.990, total=   8.5s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[15:35:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1000, score=0.991, total=   8.9s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[15:35:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1000, score=0.990, total=   8.5s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[15:35:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1000, score=0.990, total=   8.6s\n",
      "[CV] n_estimators=1200 ...............................................\n",
      "[15:35:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1200, score=0.987, total=  10.2s\n",
      "[CV] n_estimators=1200 ...............................................\n",
      "[15:35:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1200, score=0.987, total=  12.8s\n",
      "[CV] n_estimators=1200 ...............................................\n",
      "[15:35:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1200, score=0.989, total=  10.7s\n",
      "[CV] n_estimators=1200 ...............................................\n",
      "[15:36:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1200, score=0.994, total=  12.4s\n",
      "[CV] n_estimators=1200 ...............................................\n",
      "[15:36:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1200, score=0.991, total=  10.1s\n",
      "[CV] n_estimators=1200 ...............................................\n",
      "[15:36:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1200, score=0.993, total=  10.9s\n",
      "[CV] n_estimators=1200 ...............................................\n",
      "[15:36:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1200, score=0.990, total=  10.5s\n",
      "[CV] n_estimators=1200 ...............................................\n",
      "[15:36:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... n_estimators=1200, score=0.990, total=  10.0s\n",
      "[CV] n_estimators=1200 ...............................................\n",
      "[15:37:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1200, score=0.990, total=  10.0s\n",
      "[CV] n_estimators=1200 ...............................................\n",
      "[15:37:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1200, score=0.990, total=   9.7s\n",
      "[CV] n_estimators=1500 ...............................................\n",
      "[15:37:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1500, score=0.987, total=  11.2s\n",
      "[CV] n_estimators=1500 ...............................................\n",
      "[15:37:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1500, score=0.986, total=  11.2s\n",
      "[CV] n_estimators=1500 ...............................................\n",
      "[15:37:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1500, score=0.989, total=  12.0s\n",
      "[CV] n_estimators=1500 ...............................................\n",
      "[15:37:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1500, score=0.994, total=  11.1s\n",
      "[CV] n_estimators=1500 ...............................................\n",
      "[15:38:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1500, score=0.991, total=  11.0s\n",
      "[CV] n_estimators=1500 ...............................................\n",
      "[15:38:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1500, score=0.993, total=  11.1s\n",
      "[CV] n_estimators=1500 ...............................................\n",
      "[15:38:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1500, score=0.990, total=  11.1s\n",
      "[CV] n_estimators=1500 ...............................................\n",
      "[15:38:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1500, score=0.990, total=  13.5s\n",
      "[CV] n_estimators=1500 ...............................................\n",
      "[15:38:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1500, score=0.989, total=  13.6s\n",
      "[CV] n_estimators=1500 ...............................................\n",
      "[15:39:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV] ................... n_estimators=1500, score=0.990, total=  14.8s\n",
      "[15:39:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:  8.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=0.8,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=0.8,\n",
       "                                     enable_categorical=False, gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_co...\n",
       "                                     predictor=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=0.8,\n",
       "                                     tree_method=None, use_label_encoder=True,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'n_estimators': [100, 500, 700, 900, 1000, 1200,\n",
       "                                          1500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=20)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.990 (std: 0.00170)\n",
      "Parameters: {'n_estimators': 500}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.990 (std: 0.00183)\n",
      "Parameters: {'n_estimators': 700}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.990 (std: 0.00188)\n",
      "Parameters: {'n_estimators': 900}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(grid_search.cv_results_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we got n_estimator=500 as best with learning_rate=0.1  . Next we'll tune max_depth,gamma and min_child_weight, which control overfit by controlling size of individual trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params={\n",
    "            \"gamma\":[0,2,5,8,10],\n",
    "            \"max_depth\": [2,3,4,5,6,7,8],\n",
    "            \"min_child_weight\":[0.5,1,2,5,10]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2=XGBClassifier(learning_rate=0.1,n_estimators=500,\n",
    "                   subsample=0.8,colsample_bylevel=0.8,colsample_bytree=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search=RandomizedSearchCV(xgb2,\n",
    "                                 param_distributions=xgb_params,n_iter=20,cv=5,scoring='roc_auc',\n",
    "                                 n_jobs=-1,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:46:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=0.8,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=0.8,\n",
       "                                           enable_categorical=False, gamma=None,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=0.1,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monoton...\n",
       "                                           scale_pos_weight=None, subsample=0.8,\n",
       "                                           tree_method=None,\n",
       "                                           use_label_encoder=True,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   iid='deprecated', n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'gamma': [0, 2, 5, 8, 10],\n",
       "                                        'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
       "                                        'min_child_weight': [0.5, 1, 2, 5, 10]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.991 (std: 0.00136)\n",
      "Parameters: {'min_child_weight': 2, 'max_depth': 6, 'gamma': 0}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.991 (std: 0.00124)\n",
      "Parameters: {'min_child_weight': 2, 'max_depth': 7, 'gamma': 0}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.989 (std: 0.00235)\n",
      "Parameters: {'min_child_weight': 2, 'max_depth': 3, 'gamma': 0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search.cv_results_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we got best values for parameters being tuned as follows : {'min_child_weight': 1, 'gamma': 0, 'max_depth': 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is imbalance in the data , we'll look into max_delta_step and scale_pos_weight next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7261\n",
       "1     863\n",
       "Name: Revenue.Grid, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.152659099604642"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24720/7841"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params={\n",
    "            'max_delta_step':[0,1,3,6,10],\n",
    "            'scale_pos_weight':[1,2,3,4]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3=XGBClassifier(learning_rate=0.1,\n",
    "                   n_estimators=500,min_child_weight=1,\n",
    "                   gamma=0,max_depth=3,\n",
    "                   \n",
    "                  subsample=0.8,colsample_bylevel=0.8,colsample_bytree=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search=GridSearchCV(xgb3,param_grid=xgb_params,cv=5,scoring='roc_auc',n_jobs=-1,\n",
    "                         verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:50:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=0.8,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=0.8,\n",
       "                                     enable_categorical=False, gamma=0,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.1, max_delta_step=None,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=nan, monotone_constraints=N...\n",
       "                                     predictor=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=0.8,\n",
       "                                     tree_method=None, use_label_encoder=True,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_delta_step': [0, 1, 3, 6, 10],\n",
       "                         'scale_pos_weight': [1, 2, 3, 4]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.990 (std: 0.00205)\n",
      "Parameters: {'max_delta_step': 0, 'scale_pos_weight': 2}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.990 (std: 0.00205)\n",
      "Parameters: {'max_delta_step': 6, 'scale_pos_weight': 2}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.990 (std: 0.00205)\n",
      "Parameters: {'max_delta_step': 10, 'scale_pos_weight': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(grid_search.cv_results_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it turns out that , since imbalance was not that severe , defaults come out as best choices {'scale_pos_weight': 1, 'max_delta_step': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we check the effect of the noise on data and tune , subsample , colsample_bytree and colsample_bylevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params={\n",
    "            'subsample':[i/10 for i in range(5,11)],\n",
    "            'colsample_bytree':[i/10 for i in range(5,11)],\n",
    "            'colsample_bylevel':[i/10 for i in range(5,11)]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb4=XGBClassifier(learning_rate=0.1,n_estimators=500,min_child_weight=1,gamma=0,max_depth=3,\n",
    "                        scale_pos_weight=1,max_delta_step=0\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search=RandomizedSearchCV(xgb4,param_distributions=xgb_params,cv=5,n_iter=20,scoring='roc_auc',\n",
    "                                n_jobs=-1,verbose=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:54:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           enable_categorical=False, gamma=0,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=nan,\n",
       "                                           monotone_constrai...\n",
       "                                           use_label_encoder=True,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   iid='deprecated', n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bylevel': [0.5, 0.6, 0.7,\n",
       "                                                              0.8, 0.9, 1.0],\n",
       "                                        'colsample_bytree': [0.5, 0.6, 0.7, 0.8,\n",
       "                                                             0.9, 1.0],\n",
       "                                        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                                      1.0]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=20)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.989 (std: 0.00156)\n",
      "Parameters: {'subsample': 0.8, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.7}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.989 (std: 0.00152)\n",
      "Parameters: {'subsample': 0.7, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.9}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.989 (std: 0.00182)\n",
      "Parameters: {'subsample': 0.7, 'colsample_bytree': 1.0, 'colsample_bylevel': 0.9}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search.cv_results_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bets values that we got for paramaeters are as follows : {'colsample_bylevel': 0.5, 'colsample_bytree': 0.6, 'subsample': 1.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lastly we can work on L2 and L1 penalty on leaf node score to further reduce overfit if there is any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb5=XGBClassifier(learning_rate=0.1,n_estimators=500,min_child_weight=1,gamma=0,max_depth=3,\n",
    "                        scale_pos_weight=1,max_delta_step=0,\n",
    "                   colsample_bylevel= 0.5, colsample_bytree= 0.6, subsample= 1.0\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params={\n",
    "            'reg_lambda':[i/10 for i in range(0,50)],\n",
    "            'reg_alpha':[i/10 for i in range(0,50)]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search=RandomizedSearchCV(xgb5,param_distributions=xgb_params,cv=5,n_iter=20,scoring='roc_auc',\n",
    "                                n_jobs=-1,verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:56:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=0.5,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=0.6,\n",
       "                                           enable_categorical=False, gamma=0,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=nan,\n",
       "                                           monotone_constraint...\n",
       "                                                      0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                                      1.0, 1.1, 1.2, 1.3, 1.4,\n",
       "                                                      1.5, 1.6, 1.7, 1.8, 1.9,\n",
       "                                                      2.0, 2.1, 2.2, 2.3, 2.4,\n",
       "                                                      2.5, 2.6, 2.7, 2.8, 2.9, ...],\n",
       "                                        'reg_lambda': [0.0, 0.1, 0.2, 0.3, 0.4,\n",
       "                                                       0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                                       1.0, 1.1, 1.2, 1.3, 1.4,\n",
       "                                                       1.5, 1.6, 1.7, 1.8, 1.9,\n",
       "                                                       2.0, 2.1, 2.2, 2.3, 2.4,\n",
       "                                                       2.5, 2.6, 2.7, 2.8, 2.9, ...]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.987 (std: 0.00205)\n",
      "Parameters: {'reg_lambda': 1.4, 'reg_alpha': 0.2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.987 (std: 0.00178)\n",
      "Parameters: {'reg_lambda': 3.1, 'reg_alpha': 0.0}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.987 (std: 0.00223)\n",
      "Parameters: {'reg_lambda': 0.4, 'reg_alpha': 2.5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search.cv_results_,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best value that we got here is {'reg_lambda': 1.5, 'reg_alpha': 0.0}, but the performance has gone down. May be the default was doing better and wasnt picked as one of the candidates here in the random_search. we'll go with those defaults values instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb6=XGBClassifier(learning_rate=0.1,n_estimators=500,min_child_weight=1,gamma=0,max_depth=3,\n",
    "                        scale_pos_weight=1,max_delta_step=0,\n",
    "                   colsample_bylevel= 0.5, colsample_bytree= 0.6, subsample= 1.0,\n",
    "                  reg_lambda=1,reg_alpha=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to simply get cv performance of a model , without having to select any parameters we can make use of cross_validation_score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:   12.5s remaining:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   12.6s remaining:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   16.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99009948, 0.98758747, 0.98340775, 0.99056395, 0.98930104,\n",
       "       0.99173554, 0.98973349, 0.9880838 , 0.98875649, 0.98630598])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(xgb6,x_train,y_train,scoring='roc_auc',verbose=10,n_jobs=-1,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[0.92951477, 0.92590096, 0.93070889, 0.92176974, 0.92882013,\n",
    "       0.93128318, 0.93018259, 0.93297173, 0.93256565, 0.92947388]\n",
    "# these are from an earlier iteration , need not match with your current run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.929319152"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0031528442142034264"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
